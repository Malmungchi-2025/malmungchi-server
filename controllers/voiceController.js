// // controllers/voiceController.js
// const axios = require('axios');
// const FormData = require('form-data');
// const textToSpeech = require('@google-cloud/text-to-speech');
// const http  = require('http');
// const https = require('https');
// const { getPrompt, COMMON, JOB, WORK, DAILY } = require('../server/prompts');
// //const { getPrompt, COMMON, JOB, WORK, DAILY } = require('../prompts');

// const OA_BASE = 'https://api.openai.com/v1';
// const OA_KEY  = process.env.OPENAI_API_KEY;
// const STT_MODEL = process.env.STT_MODEL || 'gpt-4o-mini-transcribe'; // ì‹¤íŒ¨ ì‹œ whisper-1 í´ë°±
// const GPT_MODEL = process.env.GPT_MODEL || 'gpt-4o-mini';

// // ì•ˆì •ì„±: ì¬ì‚¬ìš© ì†Œì¼“ ë„ê¸°(ê°„ë‹¨ ëª¨ë“œ)
// const oa = axios.create({
//     baseURL: OA_BASE,
//     headers: { Authorization: `Bearer ${OA_KEY}` },
//     timeout: 120000,                         // â† 120s
//     httpAgent: new http.Agent({ keepAlive: false }),
//     httpsAgent: new https.Agent({ keepAlive: false }),
//     maxBodyLength: 1024 * 1024 * 50          // ì—¬ìœ  50MB
//   });

// const gttsClient = new textToSpeech.TextToSpeechClient();

// /**
//  * GET /api/voice/prompts?mode=job|work|daily
//  * ì•±ì˜ 'ë…¸íŠ¸íŒ¨ë“œ'ì— ë‚´ë ¤ì¤„ í”„ë¡¬í”„íŠ¸ ì›ë¬¸
//  */
// exports.getVoicePrompt = async (req, res) => {
//   try {
//     const mode = String(req.query?.mode || 'job').toLowerCase();
//     let title = 'ì·¨ì—…ì¤€ë¹„', text = `${COMMON}\n\n${JOB}`;
//     if (mode === 'work')  { title = 'ì—…ë¬´';      text = `${COMMON}\n\n${WORK}`; }
//     if (mode === 'daily') { title = 'ì¼ìƒëŒ€í™”';  text = `${COMMON}\n\n${DAILY}`; }
//     return res.json({ success: true, mode, title, prompt: text });
//   } catch (e) {
//     console.error('getVoicePrompt error:', e?.message || e);
//     return res.status(500).json({ success:false, message:'í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ì‹¤íŒ¨' });
//   }
// };

// /**
//  * POST /api/voice/chat
//  * form-data: audio=<file> (m4a/mp3/wav), mode=job|work|daily, (opt) systemPrompt, temperature
//  * ì‘ë‹µ: { success, mode, text, audioBase64, mimeType, hint }
//  */
// exports.voiceChat = async (req, res) => {
//   try {
//     if (!req.file) {
//       return res.status(400).json({ success:false, message:'audio íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.(form-data: audio)' });
//     }

//     // 1) STT
//     const fd = new FormData();
//     fd.append('file', req.file.buffer, { filename: req.file.originalname || 'audio.m4a' });
//     fd.append('model', STT_MODEL);

//     let sttResp;
//     try {
//       sttResp = await oa.post('/audio/transcriptions', fd, { headers: fd.getHeaders() });
//     } catch (e) {
//       // gpt-4o-mini-transcribe ë¯¸ì§€ì›/ì‹¤íŒ¨ ì‹œ whisper-1 í´ë°±
//       const fd2 = new FormData();
//       fd2.append('file', req.file.buffer, { filename: req.file.originalname || 'audio.m4a' });
//       fd2.append('model', 'whisper-1');
//       sttResp = await oa.post('/audio/transcriptions', fd2, { headers: fd2.getHeaders() });
//     }
//     const userText = (sttResp.data?.text || '').trim();
//     if (!userText) return res.status(400).json({ success:false, message:'ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.' });

//     // 2) GPT (modeë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
//     const mode = String(req.body?.mode || 'job').toLowerCase();
//     const baseSystem = getPrompt(mode);
//     const systemOverride = req.body?.systemPrompt ? String(req.body.systemPrompt) : '';
//     const systemPrompt = systemOverride ? `${baseSystem}\n\n---\n(override)\n${systemOverride}` : baseSystem;

//     const temperature  = Number(req.body?.temperature ?? 0.6);
//     const gpt = await oa.post('/chat/completions', {
//       model: GPT_MODEL,
//       messages: [
//         { role:'system', content: systemPrompt },
//         { role:'user',   content: userText }
//       ],
//       temperature,
//       max_tokens: 400
//     });

//     const botText = (gpt.data?.choices?.[0]?.message?.content || '').trim();
//     if (!botText) return res.status(500).json({ success:false, message:'GPT ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤.' });

//     // 3) TTS (Google Cloud â†’ MP3)
//     const [ttsResp] = await gttsClient.synthesizeSpeech({
//         input: { text: botText },
//         voice: { languageCode: 'ko-KR', ssmlGender: 'NEUTRAL' },
//         audioConfig: { audioEncoding: 'MP3', speakingRate: 1.0 }
//     });
    
//     // ğŸ”» ê³µí†µ ë²„í¼
//     const mp3Buffer = Buffer.from(ttsResp.audioContent);
    
//     // âœ… (A) ë°”ì´ë„ˆë¦¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ: Accept: audio/mpeg ì´ê±°ë‚˜ ?as=stream ì¸ ê²½ìš°
//     if (req.query.as === 'stream' || (req.get('accept') || '').includes('audio/mpeg')) {
//         res.setHeader('Content-Type', 'audio/mpeg');
//         res.setHeader('Content-Length', mp3Buffer.length);
//         return res.end(mp3Buffer);
//     }
    
//     // âœ… (B) ê¸°ì¡´ ë°©ì‹(JSON + base64) - ëª¨ë°”ì¼/ë””ë²„ê¹…ì— í¸í•¨
//     const audioBase64 = mp3Buffer.toString('base64');
//     return res.json({
//         success: true,
//         mode,
//         userText,
//         text: botText,
//         audioBase64,
//         mimeType: 'audio/mpeg',
//         hint: 'ë‹¤ì‹œ í•œ ë²ˆ í•´ë³¼ê¹Œìš”?'
//     });
//   } catch (err) {
//     console.error('voiceChat error:', err?.response?.data || err.message);
//     // OpenAI/ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ êµ¬ë¶„ ì—†ì´ ë‹¨ìˆœí™”
//     return res.status(500).json({ success:false, message:'voiceChat ì‹¤íŒ¨' });
//   }
// };

// controllers/voiceController.js
const axios = require('axios');
const FormData = require('form-data');
const http  = require('http');
const https = require('https');
const { getPrompt, COMMON, JOB, WORK, DAILY } = require('../server/prompts');
const { ttsClient, meta: ttsMeta } = require('../services/ttsClient');

const OA_BASE    = 'https://api.openai.com/v1';
const OA_KEY     = process.env.OPENAI_API_KEY;
const STT_MODEL  = process.env.STT_MODEL  || 'gpt-4o-mini-transcribe'; // ì‹¤íŒ¨ ì‹œ whisper-1 í´ë°±
const GPT_MODEL  = process.env.GPT_MODEL  || 'gpt-4o-mini';

if (!OA_KEY) {
  console.warn('[OpenAI] OPENAI_API_KEY ë¯¸ì„¤ì •: STT/GPT í˜¸ì¶œ ì‹œ 401 ë°œìƒ ê°€ëŠ¥');
}

const oa = axios.create({
  baseURL: OA_BASE,
  headers: { Authorization: `Bearer ${OA_KEY}` },
  timeout: 120000,
  httpAgent:  new http.Agent({ keepAlive: false }),
  httpsAgent: new https.Agent({ keepAlive: false }),
  maxBodyLength: 1024 * 1024 * 50
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// GET /api/voice/prompts?mode=job|work|daily
// ë…¸íŠ¸íŒ¨ë“œìš© ì›ë¬¸ í”„ë¡¬í”„íŠ¸
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
exports.getVoicePrompt = async (req, res) => {
  try {
    const mode = String(req.query?.mode || 'job').toLowerCase();
    let title = 'ì·¨ì—…ì¤€ë¹„', text = `${COMMON}\n\n${JOB}`;
    if (mode === 'work')  { title = 'ì—…ë¬´';      text = `${COMMON}\n\n${WORK}`; }
    if (mode === 'daily') { title = 'ì¼ìƒëŒ€í™”';  text = `${COMMON}\n\n${DAILY}`; }
    return res.json({ success: true, mode, title, prompt: text });
  } catch (e) {
    console.error('getVoicePrompt error:', e?.message || e);
    return res.status(500).json({ success:false, message:'í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ì‹¤íŒ¨' });
  }
};

// ê³µí†µ: ì—ëŸ¬ ë””ë²„ê¹… í—¬í¼(ë¯¼ê°ì •ë³´ ì œì™¸)
function logTtsError(tag, err) {
  const msg = err?.message || err;
  const code = err?.code;
  const details = err?.details || err?.response?.data;
  console.error(`[${tag}] TTS error:`, { msg, code, details, ttsProject: ttsMeta?.projectId, ttsEmail: ttsMeta?.clientEmailMasked });
}

function logOpenAiError(tag, err) {
  const msg = err?.message || err;
  const status = err?.response?.status;
  const data = err?.response?.data;
  console.error(`[${tag}] OpenAI error:`, { msg, status, data });
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// GET /api/voice/hello?mode=job|work|daily&as=stream
// ì„œë²„ê°€ ë¨¼ì € ìƒí™©+ì§ˆë¬¸ì„ ìŒì„±(TTS)+í…ìŠ¤íŠ¸ë¡œ ì œê³µ
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
exports.voiceHello = async (req, res) => {
  try {
    const mode = String(req.query?.mode || 'job').toLowerCase();

    // ëª¨ë“œë³„ ìŠ¤íƒ€í„° ë©”ì‹œì§€(ì¹œêµ¬ì²˜ëŸ¼, ì§§ê³  ëª…í™•í•˜ê²Œ)
    let text = '';
    if (mode === 'work') {
      text = `[ì—…ë¬´ ìƒí™© ì‹œë®¬ë ˆì´ì…˜]\nìƒí™©: íŒ€ì¥ë‹˜ê»˜ íšŒì˜ ì¼ì •ì„ ë³€ê²½ ìš”ì²­í•´ì•¼ í•´ìš”.\nQ. ë‚´ì¼ ì˜¤í›„ 2ì‹œë¡œ ë³€ê²½ì„ ì •ì¤‘í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì²­í•´ë³´ì„¸ìš”. ì‚¬ìœ ë„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ë¶™ì—¬ì£¼ì„¸ìš”.`;
    } else if (mode === 'daily') {
      text = `ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë• ë‚˜ìš”? í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ë´ìš” :) ê¸°ë»¤ë˜ ì¼ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•˜ë˜ ì¼, ë­ë“  ì¢‹ì•„ìš”.`;
    } else {
      // job (ì·¨ì—…)
      text = `ë©´ì ‘ ì—°ìŠµì„ ì‹œì‘í•´ë³¼ê¹Œìš”?\nQ. ìê¸°ì†Œê°œë¥¼ 1ë¶„ ì´ë‚´ë¡œ ë§í•´ë³´ì„¸ìš”. í•µì‹¬ ê°•ì  2ê°€ì§€ë¥¼ ê¼­ ë„£ì–´ì£¼ì„¸ìš”.`;
    }

    // TTS (Google Cloud â†’ MP3)
    const [ttsResp] = await ttsClient.synthesizeSpeech({
      input: { text },
      voice: { languageCode: 'ko-KR', ssmlGender: 'NEUTRAL' },
      audioConfig: { audioEncoding: 'MP3', speakingRate: 1.0 }
    });
    const mp3Buffer = Buffer.from(ttsResp.audioContent);

    // ë°”ì´ë„ˆë¦¬ ìŠ¤íŠ¸ë¦¬ë° ë˜ëŠ” JSON(+base64)
    if (req.query.as === 'stream' || (req.get('accept') || '').includes('audio/mpeg')) {
      res.setHeader('Content-Type', 'audio/mpeg');
      res.setHeader('Content-Length', mp3Buffer.length);
      return res.end(mp3Buffer);
    }
    return res.json({
      success: true,
      mode,
      text,
      audioBase64: mp3Buffer.toString('base64'),
      mimeType: 'audio/mpeg'
    });
  } catch (err) {
    logTtsError('voiceHello', err);
    return res.status(500).json({ success:false, message:'voiceHello ì‹¤íŒ¨', hint: err?.message });
  }
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// POST /api/voice/chat  (multipart: audio, mode, â€¦)
// STT â†’ GPT â†’ TTS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
exports.voiceChat = async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ success:false, message:'audio íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.(form-data: audio)' });
    }

    // 1) STT (ìš°ì„  gpt-4o-mini-transcribe, ì‹¤íŒ¨ ì‹œ whisper-1)
    let sttText = '';
    try {
      const fd = new FormData();
      fd.append('file', req.file.buffer, { filename: req.file.originalname || 'audio.m4a' });
      fd.append('model', STT_MODEL);
      const sttResp = await oa.post('/audio/transcriptions', fd, { headers: fd.getHeaders() });
      sttText = (sttResp.data?.text || '').trim();
    } catch (sttErr) {
      logOpenAiError('STT-primary', sttErr);
      try {
        const fd2 = new FormData();
        fd2.append('file', req.file.buffer, { filename: req.file.originalname || 'audio.m4a' });
        fd2.append('model', 'whisper-1');
        const sttResp2 = await oa.post('/audio/transcriptions', fd2, { headers: fd2.getHeaders() });
        sttText = (sttResp2.data?.text || '').trim();
      } catch (sttErr2) {
        logOpenAiError('STT-fallback', sttErr2);
        return res.status(502).json({ success:false, message:'STT ì‹¤íŒ¨', hint: sttErr2?.message });
      }
    }

    if (!sttText) {
      return res.status(400).json({ success:false, message:'ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.' });
    }

    // 2) GPT (ëª¨ë“œë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
    const mode = String(req.body?.mode || 'job').toLowerCase();
    const baseSystem = getPrompt(mode);
    const systemOverride = req.body?.systemPrompt ? String(req.body.systemPrompt) : '';
    const systemPrompt = systemOverride ? `${baseSystem}\n\n---\n(override)\n${systemOverride}` : baseSystem;

    const temperature  = Number(req.body?.temperature ?? 0.6);

    let botText = '';
    try {
      const gpt = await oa.post('/chat/completions', {
        model: GPT_MODEL,
        messages: [
          { role:'system', content: systemPrompt },
          { role:'user',   content: sttText }
        ],
        temperature,
        max_tokens: 400
      });
      botText = (gpt.data?.choices?.[0]?.message?.content || '').trim();
    } catch (gptErr) {
      logOpenAiError('GPT', gptErr);
      return res.status(502).json({ success:false, message:'GPT í˜¸ì¶œ ì‹¤íŒ¨', hint: gptErr?.message });
    }

    if (!botText) {
      return res.status(500).json({ success:false, message:'GPT ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤.' });
    }

    // 3) TTS (Google â†’ MP3)
    let mp3Buffer;
    try {
      const [ttsResp] = await ttsClient.synthesizeSpeech({
        input: { text: botText },
        voice: { languageCode: 'ko-KR', ssmlGender: 'NEUTRAL' },
        audioConfig: { audioEncoding: 'MP3', speakingRate: 1.0 }
      });
      mp3Buffer = Buffer.from(ttsResp.audioContent);
    } catch (ttsErr) {
      logTtsError('voiceChat', ttsErr);
      return res.status(502).json({ success:false, message:'TTS ì‹¤íŒ¨', hint: ttsErr?.message });
    }

    // ë°”ì´ë„ˆë¦¬ ìŠ¤íŠ¸ë¦¬ë° or JSON(+base64)
    if (req.query.as === 'stream' || (req.get('accept') || '').includes('audio/mpeg')) {
      res.setHeader('Content-Type', 'audio/mpeg');
      res.setHeader('Content-Length', mp3Buffer.length);
      return res.end(mp3Buffer);
    }

    return res.json({
      success: true,
      mode,
      userText: sttText,
      text: botText,
      audioBase64: mp3Buffer.toString('base64'),
      mimeType: 'audio/mpeg',
      hint: 'ë‹¤ì‹œ í•œ ë²ˆ í•´ë³¼ê¹Œìš”?'
    });
  } catch (err) {
    console.error('voiceChat error (top):', err?.message || err);
    return res.status(500).json({ success:false, message:'voiceChat ì‹¤íŒ¨', hint: err?.message });
  }
};